{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sparse Matrices are Used Early in Data Ingestion Development\n",
    "Once a well-trained machine learning model has been deployed, the data ingestion pipeline for that model will also be deployed. That pipeline will consist of a collection \n",
    "of tools and systems used to fetch, transform, and feed data to the machine learning system in production.\n",
    "\n",
    "However, that pipeline cannot be finalized during the development of the machine learning model it feeds. Finalizing the process of data ingestion before models \n",
    "have been run and your hypotheses about the business use case have been tested often leads to lots of re-work. Early experiments almost always \n",
    "fail and you should be careful about investing large amounts of time in building a data ingestion pipeline until there is enough accumulated evidence \n",
    "that a deployed model will help the business.\n",
    "\n",
    "Instead of building a complete data ingestion pipeline, data scientists will often use sparse matrices during the development and testing of a machine learning model. \n",
    "Sparse matrices are used to represent complex sets of data (e.g., word counts) in a way that reduces the use of computer memory and processing time.\n",
    "\n",
    "There are Python libraries available in the SciPy package to work with sparse matrices. The code block below imports this library as well as NumPy for calculations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSparse matrices offer a middle-ground between a comprehensive data warehouse solution with extensive test coverage and a directory of text files and database dumps. \\nSparse matrices do not work for all data types, but in situations where they are an appropriate technology you can leverage them even under load in production. \\nLets use an example to see how this process might play out.\\n\\nA sparse matrix is one in which most of the values are zero. If the number of zero-valued elements divided by the size of the matrix is greater than 0.5 \\nthen it is consider\\xa0sparse.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sparse matrices offer a middle-ground between a comprehensive data warehouse solution with extensive test coverage and a directory of text files and database dumps. \n",
    "Sparse matrices do not work for all data types, but in situations where they are an appropriate technology you can leverage them even under load in production. \n",
    "Lets use an example to see how this process might play out.\n",
    "\n",
    "A sparse matrix is one in which most of the values are zero. If the number of zero-valued elements divided by the size of the matrix is greater than 0.5 \n",
    "then it is consider sparse.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4992\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randint(0,2,100000).reshape(100,1000)\n",
    "sparcity = 1.0 - (np.count_nonzero(A) / A.size)\n",
    "print(round(sparcity,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Very large matrices require significant amounts of memory. If we make a matrix of counts for a document or a book where the features are all known English words, \n",
    "the chances are high that your personal machine does not have enough memory to represent it as a dense matrix. Sparse matrices have the additional advantage \n",
    "of getting around time-complexity issues that arise with operations on large dense matrices.\n",
    "\n",
    "WARNING: Many of the common functions like np.dot do not work on sparse matrices. \n",
    "See the scipy.sparse docs to learn about the specific functions for matrix products.\n",
    "\n",
    "Some of the common applications of sparse matrices are:\n",
    "\n",
    "    word counts with a large vocabulary\n",
    "    recommender systems\n",
    "    large networks\n",
    "\n",
    "There are different types of sparse matrix representations in Python available through SciPy. The most commonly used are:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A <class 'numpy.ndarray'> (10, 100) \n",
      "B <class 'scipy.sparse._coo.coo_matrix'> (10, 100) \n",
      "C <class 'numpy.matrix'> (10, 100) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sparse matrix built from the COOrdinates and values of the non-zero entries.\n",
    "A = np.random.poisson(0.3, (10,100))\n",
    "B = sparse.coo_matrix(A)\n",
    "C = B.todense()\n",
    "\n",
    "print(\"A\",type(A),A.shape,\"\\n\"\n",
    "      \"B\",type(B),B.shape,\"\\n\"\n",
    "      \"C\",type(C),C.shape,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When there are repeated entries in the rows or cols, we can remove the redundancy by indicating the location of the first occurrence \n",
    "# of a value and its increment instead of the full coordinates. When the repeats occur in colums we use a CSC format.\n",
    "A = np.random.poisson(0.3, (10,100))\n",
    "B = sparse.csc_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "# Like the CSC format there is a CSR format to account for data that repeat along the rows\n",
    "A = np.random.poisson(0.3, (10,100))\n",
    "B = sparse.csr_matrix(A)\n",
    "\n",
    "# Because the coordinate format is easier to create, it is common to create it first then cast to another more efficient format. \n",
    "# Let us first show how to create a matrix from coordinates:\n",
    "rows = [0,1,2,8]\n",
    "cols = [1,0,4,8]\n",
    "vals = [1,2,1,4]\n",
    "\n",
    "A = sparse.coo_matrix((vals, (rows, cols)))\n",
    "print(A.todense())\n",
    "\n",
    "# Then to cast it to a CSR matrix\n",
    "B = A.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because this introduction to sparse matrices is applied to data ingestion we would need to be able to:\n",
    "\n",
    "    concatenate matrices (e.g., add a new user to a recommender matrix)\n",
    "    read and write the matrices to and from disk\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 9) (1, 9)\n",
      "[[0 1 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 4]\n",
      " [0 1 0 0 2 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "## matrix merge example\n",
    "C = sparse.csr_matrix(np.array([0,1,0,0,2,0,0,0,1]).reshape(1,9))\n",
    "print(B.shape,C.shape)\n",
    "\n",
    "D = sparse.vstack([B,C])\n",
    "print(D.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9)\n"
     ]
    }
   ],
   "source": [
    "## read and write\n",
    "file_name = \"sparse_matrix.npz\"\n",
    "sparse.save_npz(file_name, D)\n",
    "E = sparse.load_npz(file_name)\n",
    "print(E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see the syntax is very similar to NumPy.  Additionally, sklearn’s train_test_split is scipy.sparse matrices aware so you can call it directly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
