{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part e: CNN DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a CNN to classify images in the CIFAR-10 Dataset\n",
    "\n",
    "We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The 10 classes are:\n",
    "\n",
    "<ol start=\"0\">\n",
    "<li> airplane\n",
    "<li>  automobile\n",
    "<li> bird\n",
    "<li>  cat\n",
    "<li> deer\n",
    "<li> dog\n",
    "<li>  frog\n",
    "<li>  horse\n",
    "<li>  ship\n",
    "<li>  truck\n",
    "</ol>\n",
    "\n",
    "For details about CIFAR-10 see:\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "For a compilation of published performance results on CIFAR 10, see:\n",
    "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
    "\n",
    "---\n",
    "\n",
    "### Building Convolutional Neural Nets\n",
    "\n",
    "In this exercise we will build and train our first convolutional neural networks.  In the first part, we walk through the different layers and how they are configured.  In the second part, you will build your own model, train it, and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n                         ^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/imp.py\", line 343, in load_dynamic\n    return _load(spec)\n           ^^^^^^^^^^^\nImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so, 0x000A): tried: '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/__init__.py:49\u001b[0m\n\u001b[1;32m     48\u001b[0m sys\u001b[39m.\u001b[39msetdlopenflags(_default_dlopen_flags \u001b[39m|\u001b[39m ctypes\u001b[39m.\u001b[39mRTLD_GLOBAL)\n\u001b[0;32m---> 49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m     50\u001b[0m sys\u001b[39m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[39mreturn\u001b[39;00m _mod\n\u001b[0;32m---> 28\u001b[0m _pywrap_tensorflow \u001b[39m=\u001b[39m swig_import_helper()\n\u001b[1;32m     29\u001b[0m \u001b[39mdel\u001b[39;00m swig_import_helper\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py:24\u001b[0m, in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m     _mod \u001b[39m=\u001b[39m imp\u001b[39m.\u001b[39;49mload_module(\u001b[39m'\u001b[39;49m\u001b[39m_pywrap_tensorflow\u001b[39;49m\u001b[39m'\u001b[39;49m, fp, pathname, description)\n\u001b[1;32m     25\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/imp.py:243\u001b[0m, in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m         \u001b[39mreturn\u001b[39;00m load_dynamic(name, filename, file)\n\u001b[1;32m    244\u001b[0m \u001b[39melif\u001b[39;00m type_ \u001b[39m==\u001b[39m PKG_DIRECTORY:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/imp.py:343\u001b[0m, in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m spec \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mmachinery\u001b[39m.\u001b[39mModuleSpec(\n\u001b[1;32m    342\u001b[0m     name\u001b[39m=\u001b[39mname, loader\u001b[39m=\u001b[39mloader, origin\u001b[39m=\u001b[39mpath)\n\u001b[0;32m--> 343\u001b[0m \u001b[39mreturn\u001b[39;00m _load(spec)\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so, 0x000A): tried: '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#from tensorflow.keras.datasets import cifar10\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#from tensorflow.keras.preprocessing.image import ImageDataGenerator\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m#from tensorflow.keras.models import Sequential\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m#from tensorflow.keras.layers import Conv2D, MaxPooling2D\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m cifar10\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/models/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/engine/functional.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m layout_map \u001b[39mas\u001b[39;00m layout_map_lib\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/__init__.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     23\u001b[0m \u001b[39m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[39m# Lazily import the `tf.contrib` module. This avoids loading all of the\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m# dependencies of `tf.contrib` at `import tensorflow` time.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_LazyContribLoader\u001b[39;00m(\u001b[39mobject\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/__init__.py:60\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m   msg \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mError importing tensorflow.  Unless you are using bazel,\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[39myou should not try to import tensorflow from its source directory;\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[39mplease exit the tensorflow source tree, and relaunch your python interpreter\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[39mfrom there.\u001b[39m\u001b[39m\"\"\"\u001b[39m \u001b[39m%\u001b[39m traceback\u001b[39m.\u001b[39mformat_exc()\n\u001b[0;32m---> 60\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[1;32m     62\u001b[0m \u001b[39m# Protocol buffers\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph_pb2\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n                         ^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/imp.py\", line 343, in load_dynamic\n    return _load(spec)\n           ^^^^^^^^^^^\nImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so, 0x000A): tried: '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/_pywrap_tensorflow.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there."
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#from tensorflow.keras.datasets import cifar10\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Each image is a 32 x 32 x 3 numpy array\n",
    "x_train[444].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's look at one of the images\n",
    "\n",
    "print(y_train[444])\n",
    "plt.imshow(x_train[444]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position\n",
    "y_train[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, let's make everything float and scale\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Layers for CNNs\n",
    "- Previously we built Neural Networks using primarily the Dense, Activation and Dropout Layers.\n",
    "\n",
    "- Here we will describe how to use some of the CNN-specific layers provided by Keras\n",
    "\n",
    "### Conv2D\n",
    "\n",
    "```python\n",
    "keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
    "```\n",
    "\n",
    "A few parameters explained:\n",
    "- `filters`: the number of filter used per location.  In other words, the depth of the output.\n",
    "- `kernel_size`: an (x,y) tuple giving the height and width of the kernel to be used\n",
    "- `strides`: and (x,y) tuple giving the stride in each dimension.  Default is `(1,1)`\n",
    "- `input_shape`: required only for the first layer\n",
    "\n",
    "Note, the size of the output will be determined by the kernel_size, strides\n",
    "\n",
    "### MaxPooling2D\n",
    "`keras.layers.pooling.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)`\n",
    "\n",
    "- `pool_size`: the (x,y) size of the grid to be pooled.\n",
    "- `strides`: Assumed to be the `pool_size` unless otherwise specified\n",
    "\n",
    "### Flatten\n",
    "Turns its input into a one-dimensional vector (per instance).  Usually used when transitioning between convolutional layers and fully connected layers.\n",
    "\n",
    "---\n",
    "\n",
    "## First CNN\n",
    "Below we will build our first CNN.  For demonstration purposes (so that it will train quickly) it is not very deep and has relatively few parameters.  We use strides of 2 in the first two convolutional layers which quickly reduces the dimensions of the output.  After a MaxPooling layer, we flatten, and then have a single fully connected layer before our final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               147968    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 181,162\n",
      "Trainable params: 181,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "\n",
    "## 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 181K parameters, even though this is a \"small\" model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 46s 929us/step - loss: 1.7298 - accuracy: 0.3685 - val_loss: 1.4571 - val_accuracy: 0.4693\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 45s 910us/step - loss: 1.4334 - accuracy: 0.4829 - val_loss: 1.2668 - val_accuracy: 0.5517\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 43s 854us/step - loss: 1.3231 - accuracy: 0.5265 - val_loss: 1.2413 - val_accuracy: 0.5481\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 1.2621 - accuracy: 0.5500 - val_loss: 1.1371 - val_accuracy: 0.6016\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 1.2135 - accuracy: 0.5686 - val_loss: 1.1789 - val_accuracy: 0.5756\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 1.1759 - accuracy: 0.5885 - val_loss: 1.1619 - val_accuracy: 0.5920\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 1.1512 - accuracy: 0.5959 - val_loss: 1.1654 - val_accuracy: 0.5988\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 1.1242 - accuracy: 0.6061 - val_loss: 1.0787 - val_accuracy: 0.6214\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 1.1117 - accuracy: 0.6137 - val_loss: 1.0348 - val_accuracy: 0.6385\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 1.1019 - accuracy: 0.6208 - val_loss: 1.0614 - val_accuracy: 0.6337\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 26s 528us/step - loss: 1.0893 - accuracy: 0.6272 - val_loss: 1.0338 - val_accuracy: 0.6464\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 30s 599us/step - loss: 1.0878 - accuracy: 0.6248 - val_loss: 1.0257 - val_accuracy: 0.6477\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 33s 654us/step - loss: 1.0753 - accuracy: 0.6307 - val_loss: 1.0529 - val_accuracy: 0.6442\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 32s 640us/step - loss: 1.0759 - accuracy: 0.6321 - val_loss: 1.0559 - val_accuracy: 0.6347\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 1.0708 - accuracy: 0.6344 - val_loss: 1.0694 - val_accuracy: 0.6426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20b643c7408>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Our previous model had the structure:\n",
    "\n",
    "Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
    "\n",
    "(with appropriate activation functions and dropouts)\n",
    "\n",
    "1. Build a more complicated model with the following pattern:\n",
    "- Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
    "\n",
    "- Use strides of 1 for all convolutional layers.\n",
    "\n",
    "2. How many parameters does your model have?  How does that compare to the previous model?\n",
    "\n",
    "3. Train it for 5 epochs.  What do you notice about the training time, loss and accuracy numbers (on both the training and validation sets)?\n",
    "\n",
    "5. Try different structures and run times, and see how accurate your model can be.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv2D(32, (3, 3)))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv2D(64, (3, 3)))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(num_classes))\n",
    "model_2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Check number of parameters\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt_2 = keras.optimizers.RMSprop(lr=0.0005)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt_2,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 255s 5ms/step - loss: 1.5711 - accuracy: 0.4337 - val_loss: 1.2029 - val_accuracy: 0.5686\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 263s 5ms/step - loss: 1.1578 - accuracy: 0.5909 - val_loss: 1.1049 - val_accuracy: 0.6119\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 190s 4ms/step - loss: 0.9918 - accuracy: 0.6537 - val_loss: 0.9459 - val_accuracy: 0.6702\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.8942 - accuracy: 0.6887 - val_loss: 1.0118 - val_accuracy: 0.6574\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 169s 3ms/step - loss: 0.8434 - accuracy: 0.7069 - val_loss: 0.8543 - val_accuracy: 0.7012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20b65aa3948>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=5,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
